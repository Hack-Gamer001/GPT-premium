{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UbAmQUgWH1M",
        "outputId": "df258a26-9c24-4610-dc18-8b96096a1d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecciona el tipo de traductor:\n",
            "1: Traductor básico (palabra por palabra)\n",
            "2: Traductor avanzado (con modelo de atención)\n",
            "Ingresa tu opción (1 o 2): 1\n",
            "Traductor básico de inglés a español (usa solo palabras conocidas)\n",
            "Palabras permitidas: i, you, he, she, we, they, eat, drink, see, like, am, are, is, the, a, an, apple, water, book, house\n",
            "\n",
            "Escribe una frase en inglés (o 'salir'): she\n",
            "Entrada: she\n",
            "Traducción aproximada: ella\n",
            "\n",
            "Escribe una frase en inglés (o 'salir'): salir\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ============================\n",
        "# 1. Diccionario básico\n",
        "# ============================\n",
        "# Diccionario de traducción palabra por palabra\n",
        "vocab_eng = ['i', 'you', 'he', 'she', 'we', 'they', 'eat', 'drink', 'see', 'like',\n",
        "             'am', 'are', 'is', 'the', 'a', 'an', 'apple', 'water', 'book', 'house']\n",
        "\n",
        "vocab_esp = ['yo', 'tú', 'él', 'ella', 'nosotros', 'ellos', 'como', 'bebo', 'veo', 'me gusta',\n",
        "             'soy', 'eres', 'es', 'el', 'un', 'una', 'manzana', 'agua', 'libro', 'casa']\n",
        "\n",
        "# Crear diccionarios para traducción\n",
        "eng2esp = dict(zip(vocab_eng, vocab_esp))\n",
        "\n",
        "# Crear diccionarios de índices para embedding\n",
        "eng2idx = {word: idx for idx, word in enumerate(vocab_eng)}\n",
        "esp2idx = {word: idx for idx, word in enumerate(vocab_esp)}\n",
        "idx2eng = {idx: word for idx, word in enumerate(vocab_eng)}\n",
        "idx2esp = {idx: word for idx, word in enumerate(vocab_esp)}\n",
        "\n",
        "# Traductor palabra por palabra\n",
        "def translate(sentence):\n",
        "    words = sentence.lower().split()\n",
        "    translated = []\n",
        "    for word in words:\n",
        "        if word in eng2esp:\n",
        "            translated.append(eng2esp[word])\n",
        "        else:\n",
        "            translated.append(f\"[{word}]\")  # palabra desconocida\n",
        "    return ' '.join(translated)\n",
        "\n",
        "# ============================\n",
        "# 2. Utilidades del modelo\n",
        "# ============================\n",
        "\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
        "\n",
        "def positional_encoding(seq_len, d_model):\n",
        "    pos = np.arange(seq_len)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    angle_rads = pos * angle_rates\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    return angle_rads\n",
        "\n",
        "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
        "    matmul_qk = np.matmul(Q, K.transpose(0, 2, 1))\n",
        "    dk = K.shape[-1]\n",
        "    scaled_attention_logits = matmul_qk / np.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    attention_weights = softmax(scaled_attention_logits)\n",
        "    output = np.matmul(attention_weights, V)\n",
        "    return output, attention_weights\n",
        "\n",
        "def multi_head_attention(Q, K, V, num_heads):\n",
        "    batch_size, seq_len, d_model = Q.shape\n",
        "    depth = d_model // num_heads\n",
        "    outputs = []\n",
        "\n",
        "    for _ in range(num_heads):\n",
        "        q = Q.copy()\n",
        "        k = K.copy()\n",
        "        v = V.copy()\n",
        "        head, _ = scaled_dot_product_attention(q, k, v)\n",
        "        outputs.append(head)\n",
        "\n",
        "    concat = np.concatenate(outputs, axis=-1)\n",
        "    return concat\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 3. Encoder y Decoder\n",
        "# ============================\n",
        "\n",
        "def encoder(X, num_heads=2, d_model=24):\n",
        "    seq_len = X.shape[0]\n",
        "    X_with_pos = X + positional_encoding(seq_len, d_model)\n",
        "    attention = multi_head_attention(X_with_pos[np.newaxis], X_with_pos[np.newaxis], X_with_pos[np.newaxis], num_heads)\n",
        "    return attention.squeeze()\n",
        "\n",
        "def decoder(Y, encoder_output, num_heads=2, d_model=24):\n",
        "    seq_len = Y.shape[0]\n",
        "    Y_with_pos = Y + positional_encoding(seq_len, d_model)\n",
        "    masked_attention = multi_head_attention(Y_with_pos[np.newaxis], Y_with_pos[np.newaxis], Y_with_pos[np.newaxis], num_heads)\n",
        "    enc_dec_attention = multi_head_attention(masked_attention, encoder_output[np.newaxis], encoder_output[np.newaxis], num_heads)\n",
        "    return enc_dec_attention.squeeze()\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 4. Funciones de entrada y salida\n",
        "# ============================\n",
        "\n",
        "def embed_sentence(sentence, vocab_dict, d_model):\n",
        "    tokens = sentence.lower().split()\n",
        "    embedded = np.zeros((len(tokens), d_model))\n",
        "    for i, word in enumerate(tokens):\n",
        "        idx = vocab_dict.get(word, 0)\n",
        "        one_hot = np.zeros(len(vocab_dict))\n",
        "        one_hot[idx] = 1\n",
        "        embedded[i] = np.pad(one_hot, (0, d_model - len(vocab_dict)), 'constant')\n",
        "    return embedded\n",
        "\n",
        "def decode_output(output, vocab_dict):\n",
        "    result = []\n",
        "    for vec in output:\n",
        "        idx = np.argmax(vec[:len(vocab_dict)])\n",
        "        result.append(idx2esp.get(idx, '?'))\n",
        "    return ' '.join(result)\n",
        "\n",
        "\n",
        "# ============================\n",
        "# 5. Interacción con el usuario\n",
        "# ============================\n",
        "\n",
        "def run_basic_translator():\n",
        "    print(\"Traductor básico de inglés a español (usa solo palabras conocidas)\")\n",
        "    print(\"Palabras permitidas:\", ', '.join(vocab_eng))\n",
        "\n",
        "    while True:\n",
        "        inp = input(\"\\nEscribe una frase en inglés (o 'salir'): \").strip().lower()\n",
        "        if inp == \"salir\":\n",
        "            break\n",
        "        output = translate(inp)\n",
        "        print(\"Entrada:\", inp)\n",
        "        print(\"Traducción aproximada:\", output)\n",
        "\n",
        "def run_advanced_translator():\n",
        "    d_model = 24\n",
        "    print(\"Traductor avanzado de inglés a español (solo usa palabras como: i, eat, apple, etc.)\")\n",
        "    print(\"Palabras permitidas:\", ', '.join(vocab_eng))\n",
        "\n",
        "    while True:\n",
        "        input_sentence = input(\"\\nEscribe una frase en inglés (o 'salir'): \").strip().lower()\n",
        "        if input_sentence == 'salir':\n",
        "            break\n",
        "\n",
        "        words = input_sentence.split()\n",
        "        if all(word in vocab_eng for word in words):\n",
        "            X = embed_sentence(input_sentence, eng2idx, d_model)\n",
        "            encoded = encoder(X)\n",
        "            decoded = decoder(X, encoded)\n",
        "            translated = decode_output(decoded, esp2idx)\n",
        "\n",
        "            print(\"Entrada:\", input_sentence)\n",
        "            print(\"Traducción aproximada:\", translated)\n",
        "        else:\n",
        "            print(\"❌ Solo se permiten palabras del vocabulario definido.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Selecciona el tipo de traductor:\")\n",
        "    print(\"1: Traductor básico (palabra por palabra)\")\n",
        "    print(\"2: Traductor avanzado (con modelo de atención)\")\n",
        "\n",
        "    choice = input(\"Ingresa tu opción (1 o 2): \")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        run_basic_translator()\n",
        "    elif choice == \"2\":\n",
        "        run_advanced_translator()\n",
        "    else:\n",
        "        print(\"Opción inválida. Ejecutando traductor básico por defecto.\")\n",
        "        run_basic_translator()"
      ]
    }
  ]
}